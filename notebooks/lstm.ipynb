{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "%run ../prepare_data.py -N_users 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191902, 82)\n"
     ]
    }
   ],
   "source": [
    "sequence = transform_users(\n",
    "    users.user_id.sample(1000)\n",
    ")\n",
    "df_train = sequence\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35802, 82)\n"
     ]
    }
   ],
   "source": [
    "sequence = transform_users(\n",
    "    users.user_id.sample(200)\n",
    ")\n",
    "df_test = sequence\n",
    "\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train total outputs: 16\n",
      "(191902, 82) (35802, 82)\n",
      "(63938, 90, 81)\n",
      "(63938, 16)\n",
      "(11904, 90, 81)\n",
      "(11904, 16)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Define number of inputs/outputs to handle\n",
    "input_size = 81\n",
    "output_size= 16\n",
    "\n",
    "# Load the train data\n",
    "...\n",
    "\n",
    "print('Train total outputs:', output_size)\n",
    "\n",
    "# Pre-process the data (normalize)\n",
    "\n",
    "# cut the input in semi-redundant sequences of maxlen characters\n",
    "maxlen = 90\n",
    "step_days = 3\n",
    "\n",
    "\n",
    "\n",
    "def reformat(df_in):\n",
    "    max_sequences = 10**5\n",
    "    days_sequence = np.empty((max_sequences,maxlen,input_size),dtype=int)\n",
    "    next_day = np.empty((max_sequences,output_size),dtype=int)\n",
    "    days = df_in[:,-1]\n",
    "    df = df_in[:,:-1]\n",
    "    \n",
    "    j=0\n",
    "    last_day = 0\n",
    "    for day_i in range(0, df.shape[0] - maxlen, step_days):\n",
    "        if last_day < days[day_i+maxlen]:\n",
    "            days_sequence[j] = df[day_i: day_i + maxlen,:input_size]\n",
    "        next_day[j] = df[day_i + maxlen,:output_size]\n",
    "        j += 1\n",
    "        last_day = days[day_i]\n",
    "\n",
    "    days_sequence = days_sequence[:j,:,:]\n",
    "    next_day = next_day[:j,:]\n",
    "    \n",
    "    return days_sequence,next_day\n",
    "\n",
    "X_train, y_train = reformat(df_train)\n",
    "X_test,y_test=reformat(df_test)\n",
    "\n",
    "print(df_train.shape,df_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_logs(history):\n",
    "    \"\"\"\n",
    "    Plot the accuracy and loss for \n",
    "        training and test sets\n",
    "    \"\"\"\n",
    "    evaluation_cost = history.history['val_loss']\n",
    "    evaluation_accuracy = history.history['val_acc']\n",
    "    training_cost = history.history['loss']\n",
    "    training_accuracy = history.history['acc']\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    f.set_figwidth(10)\n",
    "    ax1.plot(evaluation_cost,label= 'test')\n",
    "    ax1.plot(training_cost, label='train')\n",
    "    ax1.set_title('Cost')\n",
    "    ax1.legend()\n",
    "    ax2.plot(evaluation_accuracy, label='test')\n",
    "    ax2.plot(training_accuracy, label='train')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend(loc='lower right')\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate the next sequence\n",
    "    Low temperature means very conservative (picks more probable most of the time)\n",
    "    High temperature means very adventurous (picks less probable more frequently)\n",
    "    \"\"\"\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_prediction(history,days=28, maxlen=60, input_size=16, output_size=16, diversity=1):\n",
    "    \"\"\"\n",
    "    Generates as many days of prediction as requested\n",
    "    Considers maxlen days of past history (must be aligned with model)\n",
    "    \"\"\"\n",
    "    generated = np.zeros((days,output_size))\n",
    "    if history.shape[1]>maxlen:\n",
    "        x = history[:,-maxlen-1:-1,:input_size]\n",
    "    else:\n",
    "        x = history[:,:,:input_size]\n",
    "    #print(x.shape)\n",
    "    for i in range(days):\n",
    "        #print(\"Day %d\" % i)\n",
    "        preds = model.predict(x, verbose=0)[0].reshape(output_size)\n",
    "        #print(preds)\n",
    "        generated[i,:] = preds\n",
    "        \n",
    "        if input_size > output_size:\n",
    "            res = np.zeros(input_size)\n",
    "            res[:output_size] = preds\n",
    "            preds = res\n",
    "\n",
    "        #print(preds.shape)\n",
    "        #next_symptoms = sample(preds, diversity)\n",
    "        next_symptoms = preds\n",
    "        #print(next_symptoms)\n",
    "\n",
    "\n",
    "        x[:,:maxlen-1,:] = x[:,1:,:]\n",
    "        x[:,maxlen-1,:] = next_symptoms\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 63938 samples, validate on 11904 samples\n",
      "Epoch 1/500\n",
      "63938/63938 [==============================] - 127s - loss: 0.1061 - acc: 0.9778 - val_loss: 0.0832 - val_acc: 0.9830\n",
      "Epoch 2/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0823 - acc: 0.9837 - val_loss: 0.0806 - val_acc: 0.9830\n",
      "Epoch 3/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0791 - acc: 0.9837 - val_loss: 0.0777 - val_acc: 0.9830\n",
      "Epoch 4/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0777 - acc: 0.9837 - val_loss: 0.0772 - val_acc: 0.9830\n",
      "Epoch 5/500\n",
      "63938/63938 [==============================] - 123s - loss: 0.0769 - acc: 0.9837 - val_loss: 0.0771 - val_acc: 0.9830\n",
      "Epoch 6/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0772 - acc: 0.9837 - val_loss: 0.0771 - val_acc: 0.9830\n",
      "Epoch 7/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0765 - acc: 0.9837 - val_loss: 0.0762 - val_acc: 0.9830\n",
      "Epoch 8/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0758 - acc: 0.9837 - val_loss: 0.0774 - val_acc: 0.9830\n",
      "Epoch 9/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0770 - acc: 0.9834 - val_loss: 0.0777 - val_acc: 0.9830\n",
      "Epoch 10/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0755 - acc: 0.9837 - val_loss: 0.0761 - val_acc: 0.9830\n",
      "Epoch 11/500\n",
      "63938/63938 [==============================] - 123s - loss: 0.0758 - acc: 0.9837 - val_loss: 0.0765 - val_acc: 0.9830\n",
      "Epoch 12/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0748 - acc: 0.9837 - val_loss: 0.0754 - val_acc: 0.9830\n",
      "Epoch 13/500\n",
      "63938/63938 [==============================] - 124s - loss: 0.0742 - acc: 0.9837 - val_loss: 0.0750 - val_acc: 0.9830\n",
      "Epoch 14/500\n",
      "59392/63938 [==========================>...] - ETA: 8s - loss: 0.0740 - acc: 0.9836"
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "batch_size = 256\n",
    "nb_epoch = 500\n",
    "np.random.seed(131078)\n",
    "\n",
    "# build the model\n",
    "print('Build model...')\n",
    "\n",
    "\"\"\"\n",
    "filepath=\"lstm_1_layer.hdf5\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, input_size)))\n",
    "model.add(Dense(output_size))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\"\"\"\n",
    "filepath=\"lstm_2_layers_higher_dropout.hdf5\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, input_size), return_sequences=True))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(output_size))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "optimizer = adam()\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callback to save model\n",
    "save_snapshots = ModelCheckpoint(filepath,\n",
    "                                 monitor='loss',\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True,\n",
    "                                 mode='min',\n",
    "                                 verbose=0)\n",
    "callbacks_list = [save_snapshots]\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=1)          \n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])  \n",
    "\n",
    "plot_logs(history)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = X_test[0,:,:].reshape(1,maxlen,-1)\n",
    "print(hist.shape)\n",
    "res = generate_prediction(hist,maxlen=maxlen,input_size=input_size,output_size=output_size)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,:output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:28,:output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_prediction(prediction,user_id):\n",
    "    output = []\n",
    "    for i,row in enumerate(prediction):\n",
    "        for j, symptom in enumerate(row):\n",
    "            line = user_id + \",\" + i + \",\" + j + \",\" + prediction[i,j]\n",
    "            ouput.append(line)\n",
    "\n",
    "def pad_reshape_history(sequence,maxlen):\n",
    "    if sequence.shape[0] < maxlen:\n",
    "        hist = np.zeros((maxlen,sequence.shape[1]))\n",
    "        hist[maxlen-sequence.shape[0]:,:0] = sequence\n",
    "    else:\n",
    "        hist = sequence[-maxlen-1:-1,:]\n",
    "    hist = hist.reshape(1,maxlen,-1)\n",
    "\n",
    "for woman in cycle0:\n",
    "    current_id = woman.user_id\n",
    "    expected_length = np.ceil(woman.expected_cycle_length)\n",
    "    sequence = transform_users(current_id)\n",
    "    hist = pad_reshape_history(sequence,maxlen)\n",
    "    print(hist.shape)\n",
    "    res = generate_prediction(hist,maxlen=maxlen,input_size=input_size,output_size=output_size,days=expected_length)\n",
    "    print(res.shape)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

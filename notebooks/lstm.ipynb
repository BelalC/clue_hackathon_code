{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "%run ../prepare_data.py -N_users 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187426, 82)\n"
     ]
    }
   ],
   "source": [
    "sequence = transform_users(\n",
    "    users.user_id.sample(1000)\n",
    ")\n",
    "df_train = sequence\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33408, 82)\n"
     ]
    }
   ],
   "source": [
    "sequence = transform_users(\n",
    "    users.user_id.sample(200)\n",
    ")\n",
    "df_test = sequence\n",
    "\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train total outputs: 16\n",
      "(187426, 82) (33408, 82)\n",
      "(187336, 90, 16)\n",
      "(187336, 16)\n",
      "(33318, 90, 16)\n",
      "(33318, 16)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.optimizers import RMSprop, adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Define number of inputs/outputs to handle\n",
    "input_size = 16\n",
    "output_size= 16\n",
    "\n",
    "# Load the train data\n",
    "...\n",
    "\n",
    "print('Train total outputs:', output_size)\n",
    "\n",
    "# Pre-process the data (normalize)\n",
    "\n",
    "# cut the input in semi-redundant sequences of maxlen characters\n",
    "maxlen = 90\n",
    "step_days = 1\n",
    "\n",
    "\n",
    "\n",
    "def reformat(df_in):\n",
    "    max_sequences = 2*10**5\n",
    "    days_sequence = np.empty((max_sequences,maxlen,input_size),dtype=int)\n",
    "    next_day = np.empty((max_sequences,output_size),dtype=int)\n",
    "    days = df_in[:,-1]\n",
    "    df = df_in[:,:-1]\n",
    "    \n",
    "    j=0\n",
    "    last_day = 0\n",
    "    for day_i in range(0, df.shape[0] - maxlen, step_days):\n",
    "        if last_day < days[day_i+maxlen]:\n",
    "            days_sequence[j] = df[day_i: day_i + maxlen,:input_size]\n",
    "        next_day[j] = df[day_i + maxlen,:output_size]\n",
    "        j += 1\n",
    "        last_day = days[day_i]\n",
    "\n",
    "    days_sequence = days_sequence[:j,:,:]\n",
    "    next_day = next_day[:j,:]\n",
    "    \n",
    "    return days_sequence,next_day\n",
    "\n",
    "X_train, y_train = reformat(df_train)\n",
    "X_test,y_test=reformat(df_test)\n",
    "\n",
    "print(df_train.shape,df_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_logs(history):\n",
    "    \"\"\"\n",
    "    Plot the accuracy and loss for \n",
    "        training and test sets\n",
    "    \"\"\"\n",
    "    evaluation_cost = history.history['val_loss']\n",
    "    evaluation_accuracy = history.history['val_acc']\n",
    "    training_cost = history.history['loss']\n",
    "    training_accuracy = history.history['acc']\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    f.set_figwidth(10)\n",
    "    ax1.plot(evaluation_cost,label= 'test')\n",
    "    ax1.plot(training_cost, label='train')\n",
    "    ax1.set_title('Cost')\n",
    "    ax1.legend()\n",
    "    ax2.plot(evaluation_accuracy, label='test')\n",
    "    ax2.plot(training_accuracy, label='train')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend(loc='lower right')\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate the next sequence\n",
    "    Low temperature means very conservative (picks more probable most of the time)\n",
    "    High temperature means very adventurous (picks less probable more frequently)\n",
    "    \"\"\"\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_prediction(history,days=28, maxlen=60, input_size=16, output_size=16, diversity=1):\n",
    "    \"\"\"\n",
    "    Generates as many days of prediction as requested\n",
    "    Considers maxlen days of past history (must be aligned with model)\n",
    "    \"\"\"\n",
    "    generated = np.zeros((days,output_size))\n",
    "    if history.shape[1]>maxlen:\n",
    "        x = history[:,-maxlen-1:-1,:input_size]\n",
    "    else:\n",
    "        x = history[:,:,:input_size]\n",
    "    #print(x.shape)\n",
    "    for i in range(days):\n",
    "        #print(\"Day %d\" % i)\n",
    "        preds = model.predict(x, verbose=0)[0].reshape(output_size)\n",
    "        #print(preds)\n",
    "        generated[i,:] = preds\n",
    "        \n",
    "        if input_size > output_size:\n",
    "            res = np.zeros(input_size)\n",
    "            res[:output_size] = preds\n",
    "            preds = res\n",
    "\n",
    "        #print(preds.shape)\n",
    "        #next_symptoms = sample(preds, diversity)\n",
    "        next_symptoms = preds\n",
    "        #print(next_symptoms)\n",
    "\n",
    "\n",
    "        x[:,:maxlen-1,:] = x[:,1:,:]\n",
    "        x[:,maxlen-1,:] = next_symptoms\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 187336 samples, validate on 33318 samples\n",
      "Epoch 1/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0954 - acc: 0.9804 - val_loss: 0.0731 - val_acc: 0.9851\n",
      "Epoch 2/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0738 - acc: 0.9846 - val_loss: 0.0702 - val_acc: 0.9851\n",
      "Epoch 3/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0717 - acc: 0.9846 - val_loss: 0.0694 - val_acc: 0.9851\n",
      "Epoch 4/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0710 - acc: 0.9846 - val_loss: 0.0689 - val_acc: 0.9851\n",
      "Epoch 5/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0701 - acc: 0.9846 - val_loss: 0.0677 - val_acc: 0.9851\n",
      "Epoch 6/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0694 - acc: 0.9846 - val_loss: 0.0684 - val_acc: 0.9851\n",
      "Epoch 7/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0690 - acc: 0.9846 - val_loss: 0.0675 - val_acc: 0.9851\n",
      "Epoch 8/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0682 - acc: 0.9846 - val_loss: 0.0664 - val_acc: 0.9851\n",
      "Epoch 9/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0678 - acc: 0.9846 - val_loss: 0.0660 - val_acc: 0.9851\n",
      "Epoch 10/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0676 - acc: 0.9847 - val_loss: 0.0661 - val_acc: 0.9851\n",
      "Epoch 11/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0673 - acc: 0.9847 - val_loss: 0.0658 - val_acc: 0.9851\n",
      "Epoch 12/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0672 - acc: 0.9847 - val_loss: 0.0655 - val_acc: 0.9851\n",
      "Epoch 13/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0670 - acc: 0.9847 - val_loss: 0.0654 - val_acc: 0.9851\n",
      "Epoch 14/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0669 - acc: 0.9847 - val_loss: 0.0657 - val_acc: 0.9851\n",
      "Epoch 15/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0668 - acc: 0.9847 - val_loss: 0.0653 - val_acc: 0.9852\n",
      "Epoch 16/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0666 - acc: 0.9847 - val_loss: 0.0652 - val_acc: 0.9851\n",
      "Epoch 17/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0665 - acc: 0.9847 - val_loss: 0.0650 - val_acc: 0.9852\n",
      "Epoch 18/50\n",
      "187336/187336 [==============================] - 83s - loss: 0.0664 - acc: 0.9847 - val_loss: 0.0649 - val_acc: 0.9851\n",
      "Epoch 19/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0663 - acc: 0.9847 - val_loss: 0.0655 - val_acc: 0.9851\n",
      "Epoch 20/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0663 - acc: 0.9847 - val_loss: 0.0649 - val_acc: 0.9852\n",
      "Epoch 21/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0661 - acc: 0.9847 - val_loss: 0.0650 - val_acc: 0.9852\n",
      "Epoch 22/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0661 - acc: 0.9847 - val_loss: 0.0651 - val_acc: 0.9852\n",
      "Epoch 23/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0661 - acc: 0.9847 - val_loss: 0.0647 - val_acc: 0.9852\n",
      "Epoch 24/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0660 - acc: 0.9847 - val_loss: 0.0649 - val_acc: 0.9852\n",
      "Epoch 25/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0658 - acc: 0.9847 - val_loss: 0.0646 - val_acc: 0.9851\n",
      "Epoch 26/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0657 - acc: 0.9847 - val_loss: 0.0646 - val_acc: 0.9852\n",
      "Epoch 27/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0656 - acc: 0.9848 - val_loss: 0.0647 - val_acc: 0.9852\n",
      "Epoch 28/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0656 - acc: 0.9848 - val_loss: 0.0647 - val_acc: 0.9851\n",
      "Epoch 29/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0655 - acc: 0.9848 - val_loss: 0.0647 - val_acc: 0.9851\n",
      "Epoch 30/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0655 - acc: 0.9848 - val_loss: 0.0646 - val_acc: 0.9851\n",
      "Epoch 31/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0654 - acc: 0.9848 - val_loss: 0.0645 - val_acc: 0.9852\n",
      "Epoch 32/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0654 - acc: 0.9848 - val_loss: 0.0647 - val_acc: 0.9851\n",
      "Epoch 33/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0652 - acc: 0.9848 - val_loss: 0.0646 - val_acc: 0.9852\n",
      "Epoch 34/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0652 - acc: 0.9848 - val_loss: 0.0646 - val_acc: 0.9852\n",
      "Epoch 35/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0651 - acc: 0.9848 - val_loss: 0.0646 - val_acc: 0.9851\n",
      "Epoch 36/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0651 - acc: 0.9848 - val_loss: 0.0646 - val_acc: 0.9851\n",
      "Epoch 37/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0650 - acc: 0.9848 - val_loss: 0.0648 - val_acc: 0.9852\n",
      "Epoch 38/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0649 - acc: 0.9848 - val_loss: 0.0648 - val_acc: 0.9852\n",
      "Epoch 39/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0649 - acc: 0.9848 - val_loss: 0.0647 - val_acc: 0.9851\n",
      "Epoch 40/50\n",
      "187336/187336 [==============================] - 82s - loss: 0.0648 - acc: 0.9848 - val_loss: 0.0652 - val_acc: 0.9852\n",
      "Epoch 41/50\n",
      "187336/187336 [==============================] - 81s - loss: 0.0648 - acc: 0.9848 - val_loss: 0.0648 - val_acc: 0.9852\n",
      "Epoch 42/50\n",
      " 86528/187336 [============>.................] - ETA: 41s - loss: 0.0646 - acc: 0.9849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-94fb23b749a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     verbose=1)          \n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model params\n",
    "batch_size = 512\n",
    "nb_epoch = 50\n",
    "np.random.seed(131078)\n",
    "\n",
    "# build the model\n",
    "print('Build model...')\n",
    "\n",
    "\n",
    "filepath=\"lstm_1_layer.hdf5\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, input_size)))\n",
    "model.add(Dense(output_size))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\"\"\"\n",
    "filepath=\"lstm_2_layers_higher_dropout.hdf5\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, input_size), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(output_size))\n",
    "model.add(Activation('sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "optimizer = adam()\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define callback to save model\n",
    "save_snapshots = ModelCheckpoint(filepath,\n",
    "                                 monitor='loss',\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True,\n",
    "                                 mode='min',\n",
    "                                 verbose=0)\n",
    "callbacks_list = [save_snapshots]\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=1)          \n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])  \n",
    "\n",
    "plot_logs(history)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = X_test[0,:,:].reshape(1,maxlen,-1)\n",
    "print(hist.shape)\n",
    "res = generate_prediction(hist,maxlen=maxlen,input_size=input_size,output_size=output_size)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608],\n",
       "       [ 0.01095976,  0.00664205,  0.00363475,  0.01084435,  0.00173918,\n",
       "         0.00605508,  0.00538483,  0.01100782,  0.0215272 ,  0.00720003,\n",
       "         0.00308284,  0.00900103,  0.00516408,  0.00340249,  0.00277895,\n",
       "         0.00186608]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:,:output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:28,:output_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "D:\\Users\\greg_\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "def format_prediction(prediction,user_id):\n",
    "    output = []\n",
    "    prediction = pd.DataFrame(prediction)\n",
    "    for i,row in prediction.iterrows():\n",
    "        for j, symptom in enumerate(row):\n",
    "            line = [user_id,i+1,j,prediction.ix[i,j]]\n",
    "            output.append(line)\n",
    "    return output\n",
    "\n",
    "def pad_reshape_history(sequence,maxlen,input_size):\n",
    "    if sequence.shape[0] < maxlen:\n",
    "        hist = np.zeros((maxlen,sequence.shape[1]))\n",
    "        hist[maxlen-sequence.shape[0]:,:] = sequence\n",
    "    else:\n",
    "        hist = sequence[-maxlen-1:-1,:]\n",
    "    if sequence.shape[1] > input_size:\n",
    "        hist = hist[:,:input_size]\n",
    "    hist = hist.reshape(1,maxlen,-1)\n",
    "    return hist\n",
    "    \n",
    "symptoms_of_interest_dict = {\n",
    "    0:'happy',\n",
    "    1:'pms',\n",
    "    2:'sad', \n",
    "    3:'sensitive_emotion',\n",
    "    4:'energized', \n",
    "    5:'exhausted', \n",
    "    6:'high_energy', \n",
    "    7:'low_energy',\n",
    "    8:'cramps', \n",
    "    9:'headache', \n",
    "    10:'ovulation_pain', \n",
    "    11:'tender_breasts',\n",
    "    12:'acne_skin', \n",
    "    13:'good_skin', \n",
    "    14:'oily_skin', \n",
    "    15:'dry_skin'\n",
    "}\n",
    "        \n",
    "submission = []\n",
    "j = 0\n",
    "for index, woman in cycles0.iterrows():\n",
    "    current_id = woman.user_id\n",
    "    expected_length = int(np.ceil(woman.expected_cycle_length))\n",
    "    sequence = transform_user(current_id)\n",
    "    hist = pad_reshape_history(sequence,maxlen,input_size)\n",
    "    res = generate_prediction(hist,maxlen=maxlen,input_size=input_size,output_size=output_size,days=expected_length)\n",
    "    submission.append(format_prediction(res,current_id))\n",
    "    j+=1\n",
    "    if j > 2:\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.concat([pd.DataFrame(submission[i]) for i in range(len(submission))], ignore_index=True)  \n",
    "submission_df.columns = ['user_id','day_in_cycle','symptom','probability']\n",
    "submission_df[\"symptom\"] = submission_df[\"symptom\"].apply(lambda x: symptoms_of_interest_dict[x])    \n",
    "\n",
    "submission_df.to_csv(\"results.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>day_in_cycle</th>\n",
       "      <th>symptom</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>pms</td>\n",
       "      <td>0.009573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.006829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.016105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.004730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.008621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.015173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.027564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.012830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.014225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.005364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>oily_skin</td>\n",
       "      <td>0.004481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>1</td>\n",
       "      <td>dry_skin</td>\n",
       "      <td>0.001851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>pms</td>\n",
       "      <td>0.009815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.007019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.015555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.028219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.013184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.014587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>03009100-a1fa-4fad-bf9b-6102c690f3be</td>\n",
       "      <td>2</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.005521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.007044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.016523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.008893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.015594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.028287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.013228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>oily_skin</td>\n",
       "      <td>0.004631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>28</td>\n",
       "      <td>dry_skin</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.013887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>pms</td>\n",
       "      <td>0.009840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>sad</td>\n",
       "      <td>0.007044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>sensitive_emotion</td>\n",
       "      <td>0.016523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>energized</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>exhausted</td>\n",
       "      <td>0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>high_energy</td>\n",
       "      <td>0.008893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>low_energy</td>\n",
       "      <td>0.015594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>cramps</td>\n",
       "      <td>0.028287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>headache</td>\n",
       "      <td>0.013228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>ovulation_pain</td>\n",
       "      <td>0.004042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>tender_breasts</td>\n",
       "      <td>0.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>acne_skin</td>\n",
       "      <td>0.008268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>good_skin</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>oily_skin</td>\n",
       "      <td>0.004631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>9f13e16f-c845-4d69-8875-e79f3442c45c</td>\n",
       "      <td>29</td>\n",
       "      <td>dry_skin</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id  day_in_cycle            symptom  \\\n",
       "0     03009100-a1fa-4fad-bf9b-6102c690f3be             1              happy   \n",
       "1     03009100-a1fa-4fad-bf9b-6102c690f3be             1                pms   \n",
       "2     03009100-a1fa-4fad-bf9b-6102c690f3be             1                sad   \n",
       "3     03009100-a1fa-4fad-bf9b-6102c690f3be             1  sensitive_emotion   \n",
       "4     03009100-a1fa-4fad-bf9b-6102c690f3be             1          energized   \n",
       "5     03009100-a1fa-4fad-bf9b-6102c690f3be             1          exhausted   \n",
       "6     03009100-a1fa-4fad-bf9b-6102c690f3be             1        high_energy   \n",
       "7     03009100-a1fa-4fad-bf9b-6102c690f3be             1         low_energy   \n",
       "8     03009100-a1fa-4fad-bf9b-6102c690f3be             1             cramps   \n",
       "9     03009100-a1fa-4fad-bf9b-6102c690f3be             1           headache   \n",
       "10    03009100-a1fa-4fad-bf9b-6102c690f3be             1     ovulation_pain   \n",
       "11    03009100-a1fa-4fad-bf9b-6102c690f3be             1     tender_breasts   \n",
       "12    03009100-a1fa-4fad-bf9b-6102c690f3be             1          acne_skin   \n",
       "13    03009100-a1fa-4fad-bf9b-6102c690f3be             1          good_skin   \n",
       "14    03009100-a1fa-4fad-bf9b-6102c690f3be             1          oily_skin   \n",
       "15    03009100-a1fa-4fad-bf9b-6102c690f3be             1           dry_skin   \n",
       "16    03009100-a1fa-4fad-bf9b-6102c690f3be             2              happy   \n",
       "17    03009100-a1fa-4fad-bf9b-6102c690f3be             2                pms   \n",
       "18    03009100-a1fa-4fad-bf9b-6102c690f3be             2                sad   \n",
       "19    03009100-a1fa-4fad-bf9b-6102c690f3be             2  sensitive_emotion   \n",
       "20    03009100-a1fa-4fad-bf9b-6102c690f3be             2          energized   \n",
       "21    03009100-a1fa-4fad-bf9b-6102c690f3be             2          exhausted   \n",
       "22    03009100-a1fa-4fad-bf9b-6102c690f3be             2        high_energy   \n",
       "23    03009100-a1fa-4fad-bf9b-6102c690f3be             2         low_energy   \n",
       "24    03009100-a1fa-4fad-bf9b-6102c690f3be             2             cramps   \n",
       "25    03009100-a1fa-4fad-bf9b-6102c690f3be             2           headache   \n",
       "26    03009100-a1fa-4fad-bf9b-6102c690f3be             2     ovulation_pain   \n",
       "27    03009100-a1fa-4fad-bf9b-6102c690f3be             2     tender_breasts   \n",
       "28    03009100-a1fa-4fad-bf9b-6102c690f3be             2          acne_skin   \n",
       "29    03009100-a1fa-4fad-bf9b-6102c690f3be             2          good_skin   \n",
       "...                                    ...           ...                ...   \n",
       "1442  9f13e16f-c845-4d69-8875-e79f3442c45c            28                sad   \n",
       "1443  9f13e16f-c845-4d69-8875-e79f3442c45c            28  sensitive_emotion   \n",
       "1444  9f13e16f-c845-4d69-8875-e79f3442c45c            28          energized   \n",
       "1445  9f13e16f-c845-4d69-8875-e79f3442c45c            28          exhausted   \n",
       "1446  9f13e16f-c845-4d69-8875-e79f3442c45c            28        high_energy   \n",
       "1447  9f13e16f-c845-4d69-8875-e79f3442c45c            28         low_energy   \n",
       "1448  9f13e16f-c845-4d69-8875-e79f3442c45c            28             cramps   \n",
       "1449  9f13e16f-c845-4d69-8875-e79f3442c45c            28           headache   \n",
       "1450  9f13e16f-c845-4d69-8875-e79f3442c45c            28     ovulation_pain   \n",
       "1451  9f13e16f-c845-4d69-8875-e79f3442c45c            28     tender_breasts   \n",
       "1452  9f13e16f-c845-4d69-8875-e79f3442c45c            28          acne_skin   \n",
       "1453  9f13e16f-c845-4d69-8875-e79f3442c45c            28          good_skin   \n",
       "1454  9f13e16f-c845-4d69-8875-e79f3442c45c            28          oily_skin   \n",
       "1455  9f13e16f-c845-4d69-8875-e79f3442c45c            28           dry_skin   \n",
       "1456  9f13e16f-c845-4d69-8875-e79f3442c45c            29              happy   \n",
       "1457  9f13e16f-c845-4d69-8875-e79f3442c45c            29                pms   \n",
       "1458  9f13e16f-c845-4d69-8875-e79f3442c45c            29                sad   \n",
       "1459  9f13e16f-c845-4d69-8875-e79f3442c45c            29  sensitive_emotion   \n",
       "1460  9f13e16f-c845-4d69-8875-e79f3442c45c            29          energized   \n",
       "1461  9f13e16f-c845-4d69-8875-e79f3442c45c            29          exhausted   \n",
       "1462  9f13e16f-c845-4d69-8875-e79f3442c45c            29        high_energy   \n",
       "1463  9f13e16f-c845-4d69-8875-e79f3442c45c            29         low_energy   \n",
       "1464  9f13e16f-c845-4d69-8875-e79f3442c45c            29             cramps   \n",
       "1465  9f13e16f-c845-4d69-8875-e79f3442c45c            29           headache   \n",
       "1466  9f13e16f-c845-4d69-8875-e79f3442c45c            29     ovulation_pain   \n",
       "1467  9f13e16f-c845-4d69-8875-e79f3442c45c            29     tender_breasts   \n",
       "1468  9f13e16f-c845-4d69-8875-e79f3442c45c            29          acne_skin   \n",
       "1469  9f13e16f-c845-4d69-8875-e79f3442c45c            29          good_skin   \n",
       "1470  9f13e16f-c845-4d69-8875-e79f3442c45c            29          oily_skin   \n",
       "1471  9f13e16f-c845-4d69-8875-e79f3442c45c            29           dry_skin   \n",
       "\n",
       "      probability  \n",
       "0        0.013489  \n",
       "1        0.009573  \n",
       "2        0.006829  \n",
       "3        0.016105  \n",
       "4        0.002734  \n",
       "5        0.004730  \n",
       "6        0.008621  \n",
       "7        0.015173  \n",
       "8        0.027564  \n",
       "9        0.012830  \n",
       "10       0.003929  \n",
       "11       0.014225  \n",
       "12       0.008035  \n",
       "13       0.005364  \n",
       "14       0.004481  \n",
       "15       0.001851  \n",
       "16       0.013842  \n",
       "17       0.009815  \n",
       "18       0.007019  \n",
       "19       0.016481  \n",
       "20       0.002822  \n",
       "21       0.004883  \n",
       "22       0.008861  \n",
       "23       0.015555  \n",
       "24       0.028219  \n",
       "25       0.013184  \n",
       "26       0.004034  \n",
       "27       0.014587  \n",
       "28       0.008246  \n",
       "29       0.005521  \n",
       "...           ...  \n",
       "1442     0.007044  \n",
       "1443     0.016523  \n",
       "1444     0.002831  \n",
       "1445     0.004897  \n",
       "1446     0.008893  \n",
       "1447     0.015594  \n",
       "1448     0.028287  \n",
       "1449     0.013228  \n",
       "1450     0.004042  \n",
       "1451     0.014629  \n",
       "1452     0.008268  \n",
       "1453     0.005535  \n",
       "1454     0.004631  \n",
       "1455     0.001917  \n",
       "1456     0.013887  \n",
       "1457     0.009840  \n",
       "1458     0.007044  \n",
       "1459     0.016523  \n",
       "1460     0.002831  \n",
       "1461     0.004897  \n",
       "1462     0.008893  \n",
       "1463     0.015594  \n",
       "1464     0.028287  \n",
       "1465     0.013228  \n",
       "1466     0.004042  \n",
       "1467     0.014629  \n",
       "1468     0.008268  \n",
       "1469     0.005535  \n",
       "1470     0.004631  \n",
       "1471     0.001917  \n",
       "\n",
       "[1472 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
